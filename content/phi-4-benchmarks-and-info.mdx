---
title: "Phi 4 Reasoning Benchmarks, Model Specs, and Comparisons"
description: "Phi 4 Reasoning and Phi 4 Mini Reasoning benchmarks and comparisons"
date:
  created: "2025-05-02"
  updated: "2025-05-02"
author:
  name: BestCodes
image:
  url: /image/blog/phi-4-reasoning-blog-cover.png
  alt: "Banner featuring the text 'Phi 4 Reasoning' with a tagline 'Benchmarks, Comparisons, and More'."
  fit: contain
tags:
  - benchmarks
  - ai
  - ollama
  - opensource
---

## Meet the Phi 4 Reasoning series by Microsoft

Released on April 30th, 2025, the Phi 4 Reasoning model series is the latest generation of LLMs from Microsoft. It's the first model in the Phi series designed for reasoning tasks.
TL;DR: The **benchmarks** look great, but my **experience** didn't match.

Let's check it out!

---

## Model Sizes and Details

Here's a quick look at what you can choose from:

| Model               | Params | Max Context |
| ------------------- | ------ | ----------- |
| phi4-reasoning-plus | 14.7B  | 32K         |
| phi4-reasoning      | 14.7B  | 32K         |
| phi4-mini-reasoning | 3.8B   | 32K         |

Some key model details:

- All models are licensed under **MIT**. This makes them quite accessible for various applications.
- Notably, the context window isn't that great, especially for a reasoning model. Even the 8B variant of the recently released [Qwen3 model](/blog/qwen-3-what-you-need-to-know) has a larger context window.
- The training data cutoff is March 2025, but the model itself claims a cutoff date of October 2023.

## Benchmarks and Comparisons

Well, at least the benchmarks _look_ good. My experience in general was not so wonderful. Maybe this excerpt from the model description on HuggingFace helps explain why:

> [This model is designed and tested for math reasoning only.](https://huggingface.co/microsoft/Phi-4-reasoning#:~:text=This%20model%20is%20designed%20and%20tested%20for%20math%20reasoning%20only.)

Regardless, let's take a look.

---

Here, you can see that Phi 4 Reasoning performs quite well for its size. It significantly outperforms the Phi 4 base model, as well as DeepSeek Distill 70B and o1-mini in certain scenarios:

![Phi 4 Reasoning Benchmarks](/image/blog/phi4-reasoning-benchmarks/general-1.png)

Phi 4 Mini Reasoning also demonstrates strong performance, outperforming its base model and most others (with o1 being an exception in a couple of benchmarks) specifically on math reasoning tasks:

![Phi 4 Mini Reasoning Benchmarks](/image/blog/phi4-reasoning-benchmarks/mini-math.png)

## My Personal Experience

My experience with the model was okay, but it's really a math model, not a general model.

For example, let's tell Phi 4 Reasoning "Hello!". That should be easy, right?!

![Hello chat with Phi 4](/image/blog/phi4-reasoning-misc/hello-chat.png)

Apparently, "We need to produce a greeting response" is hard not to keep thinking about, because I hit a token limit before it responded.

It does, however, seem to fare better with counting and more straightforward reasoning. Here's the "Is 9.11 or 9.9 larger" test:

![Is 9.11 or 9.9 larger](/image/blog/phi4-reasoning-misc/larger-9.png)

Sometimes, the answer is okay, but the reasoning is a bit weird:

![Weird reasoning](/image/blog/phi4-reasoning-misc/weird-reasoning.png)

According to the reasoning:

> User: "What time is it?" The system: "You are Phi, a language model developed by Microsoft, trained to provide accurate, secure, and user-aligned responses." It instructs Phi to provide "accurate, secure, and user-aligned responses." And then ask: "What time is it?"

"And then ask: 'What time is it?'"?? Where did _that_ come from? LOL. At least it answered correctly in the end.

## Conclusion

Phi 4 Reasoning is definitely interesting and performs well for its size, but it doesn't quite take the lead in the general LLM landscape. I wouldn't recommend it for broad, general-purpose applications at this point. ðŸ¥²
If you're interested in the technical details, you can check out the [official release paper by Microsoft](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/phi_4_reasoning.pdf).

Thanks for reading!
